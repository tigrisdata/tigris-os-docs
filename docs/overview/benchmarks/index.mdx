# Tigris Benchmarks

export const MetricCell = ({
  serviceValue,
  tigrisValue,
  unit,
}) => {
  const diffMultiple = serviceValue / tigrisValue;
  const multiple = Math.round(diffMultiple * 100) / 100;

return ( <div style={{
        textAlign: "center",
        padding: "8px",
        verticalAlign: "middle",
      }} > <div style={{ fontWeight: "bold", fontSize: "1.125rem" }}>
{serviceValue} {unit} </div> <div
style={{ fontSize: "0.75rem", color: "#ccc" }}> ({multiple}x Tigris) </div>

</div> ); };

export const B = ({ t, unit }) => (
  <div style={{ textAlign: "center", padding: "8px" }}>
    <div style={{ fontWeight: "bold", fontSize: "1.125rem" }}>
      {t} {unit}
    </div>
  </div>
);

export const R = ({ t }) => (
  <div
    style={{
      textAlign: "center",
      verticalAlign: "middle",
      padding: "8px",
    }}
  >
    <div style={{ fontSize: "1.125rem" }}>{t}</div>
  </div>
);

export const M = ({ t, s }) => (
  <MetricCell tigrisValue={t} serviceValue={s} unit="ms" />
);

export const S = ({ t, s }) => (
  <MetricCell tigrisValue={t} serviceValue={s} unit="sec" />
);

export const O = ({ t, s }) => (
  <MetricCell tigrisValue={t} serviceValue={s} unit="ops/sec" higherIsBetter />
);

Tigris is highly optimized for storing and retrieving small objects, offering
significant performance advantages over other popular object storage solutions.

Benchmarks comparing Tigris with AWS S3 and Cloudflare R2 demonstrate that
Tigris consistently delivers higher throughput and lower latency for small
object workloads. This efficiency allows you to use a single, unified object
store for a wide range of object sizes, from very small payloads to large
multi-gigabyte blobs, without performance trade-offs.

Tigris employs several key strategies to accelerate small object workloads:

- **Inlining Small Objects:** Very small objects are inlined directly within
  their metadata records, which minimizes the I/O operations required for
  retrieval.
- **Key Coalescing:** Adjacent keys are coalesced to reduce storage
  fragmentation and overhead, improving data density and scan efficiency.
- **On-Disk Caching:** Frequently accessed ("hot") items are cached in a
  high-performance, on-disk cache backed by a Log-Structured Merge-tree (LSM),
  ensuring rapid access to popular data.

## Summary

The benchmarks show that Tigris significantly outperforms both AWS S3 and
Cloudflare R2 for small object workloads. The results show Tigris achieves:

- **Sub-10ms** read latency
- **Sub-20ms** write latency
- **4x throughput** compared to S3 for both read and write operations
- **20x throughput** compared to R2 for both read and write operations

To ensure our findings are reproducible, we outline the full benchmarking
methodology and provide links to all artifacts.

## Benchmark Setup

The [Yahoo Cloud Serving Benchmark (YCSB)](https://en.wikipedia.org/wiki/YCSB)
was used to evaluate the three systems. We
[added support](https://github.com/pingcap/go-ycsb/pull/307) for S3-compatible
object storage systems (such as Tigris and Cloudflare R2), which was merged
shortly after publishing.

All experiments ran on a neutral cloud provider to avoid vendor-specific
optimizations. Table 1 summarizes the test instance:

_Table 1: Benchmark host configuration._

| Component         | Quantity                           |
| ----------------- | ---------------------------------- |
| Instance type     | VM.Standard.A1.Flex (Oracle Cloud) |
| Region            | us-sanjose-1 (West Coast)          |
| vCPU cores        | 32                                 |
| Memory            | 32 GiB                             |
| Network bandwidth | 32 Gbps                            |

### YCSB Configuration

We benchmarked a dataset of 10 million objects, each 1 KB in size. The
configuration is available in the
[tigrisdata-community/ycsb-benchmarks](https://github.com/tigrisdata-community/ycsb-benchmarks)
GitHub repo, specifically at
[results/10m-1kb/workloads3](https://github.com/tigrisdata-community/ycsb-benchmarks/blob/main/results/10m-1kb/workloads3).

Our buckets were placed in the following regions per provider:

| Provider      | Region                                                               |
| :------------ | :------------------------------------------------------------------- |
| Tigris        | `auto` (globally replicated, but operating against the `sjc` region) |
| AWS S3        | `us-west-1` (Northern California)                                    |
| Cloudflare R2 | `WNAM` (Western North America)                                       |

## Results

Using YCSB, we evaluated two distinct phases: (i) a bulk load of 10 million 1 KB
objects and (ii) a mixed workload of one million operations composed of 80%
reads and 20% writes.

### Loading 10 million objects

Figure 1 (below) plots the end-to-end ingestion time. Tigris finishes the load
in **6711 s**, which is roughly **31 % faster than S3 (8826 s)** and **an order
of magnitude faster than R2 (72063 s)**.

Latency drives this gap. As shown in Figure&nbsp;2, R2's p90 PUT latency tops
**340 ms** whereas Tigris stays below **36 ms** and S3 below **38 ms**.
Table&nbsp;2 summarizes the key statistics.

_Table 2: Load-phase latency and throughput metrics._

| Service          | P50 Latency (ms)             | P90 Latency (ms)             | Runtime (sec)               | Throughput (ops/sec)            |
| ---------------- | ---------------------------- | ---------------------------- | --------------------------- | ------------------------------- |
| <R t="Tigris" /> | <B t={16.799} unit="ms" />   | <B t={35.871} unit="ms" />   | <B t={6710.7} unit="sec" /> | <B t={1490.2} unit="ops/sec" /> |
| <R t="S3" />     | <M t={16.799} s={25.743} />  | <M t={35.871} s={37.791} />  | <S t={6710.7} s={8826.4} /> | <O t={1490.2} s={1133.0} />     |
| <R t="R2" />     | <M t={16.799} s={197.119} /> | <M t={35.871} s={340.223} /> | <S t={6710.7} s={72063} />  | <O t={1490.2} s={138.8} />      |

![Figure 1 – Total load time – Tigris vs S3 vs R2](./total-time-load-comparison.webp "Total load time – Tigris vs S3 vs R2")

_Figure 1: Total load time for loading 10 M 1 KB objects._

R2 takes more than 300ms to write a single object, which explains the slowness
of the data load.

While comparing Tigris latency to S3, it is still better but not by the same
margin as compared to R2.

![Figure 2 – PUT p90 latency – Tigris vs S3](./load-sjc-s3-tigris-insert-latency_p90_ms.webp "PUT p90 latency – Tigris vs S3")

_Figure 2: PUT p90 latency during load phase._

### 1 million operations (20% write, 80% read)

This is the _run_ phase of the YCSB benchmark. It is a 20% write and 80% read
workload totaling 1 million operations.

#### Read throughput

![Figure 3 – Read throughput – Tigris vs R2](./run-sjc-r2-tigris-read-throughput_ops.webp "Read throughput – Tigris vs R2")

_Figure 3: Read throughput during mixed workload (Tigris vs R2)._

![Figure 4 – Read throughput – Tigris vs S3](./run-sjc-s3-tigris-read-throughput_ops.webp "Read throughput – Tigris vs S3")

_Figure 4: Read throughput during mixed workload (Tigris vs S3)._

Throughput traces for all three providers remain stable, but the absolute rates
diverge sharply. Tigris sustains **≈3.3 k ops/s**, nearly **4 × S3 (≈ 892
ops/s)** and **20 × R2 (≈ 170 ops/s)**.

#### Read latency

![Figure 5 – Read p90 latency – Tigris vs R2](./run-sjc-r2-tigris-read-latency_p90_ms.webp "Read p90 latency – Tigris vs R2")

_Figure 5: Read p90 latency during mixed workload (Tigris vs R2)._

![Figure 6 – Read p90 latency – Tigris vs S3](./run-sjc-s3-tigris-read-latency_p90_ms.webp "Read p90 latency – Tigris vs S3")

_Figure 6: Read p90 latency during mixed workload (Tigris vs S3)._

Latency follows the same pattern. Tigris keeps p90 below **8 ms**; S3 settles
around **42 ms**, and R2 stretches beyond **199 ms**.

#### Write throughput

![Figure 7 – Write throughput – Tigris vs R2](./run-sjc-r2-tigris-update-throughput_ops.webp "Write throughput – Tigris vs R2")

_Figure 7: Write throughput during mixed workload (Tigris vs R2)._

![Figure 8 – Write throughput – Tigris vs S3](./run-sjc-s3-tigris-update-throughput_ops.webp "Write throughput – Tigris vs S3")

_Figure 8: Write throughput during mixed workload (Tigris vs S3)._

Write throughput shows the same spread. Tigris delivers **≈ 828 ops/s**, close
to **4 × S3 (224 ops/s)** and **20 × R2 (43 ops/s)**.

#### Write latency

![Figure 9 – Write p90 latency – Tigris vs R2](./run-sjc-r2-tigris-update-latency_p90_ms.webp "Write p90 latency – Tigris vs R2")

_Figure 9: Write p90 latency during mixed workload (Tigris vs R2)._

![Figure 10 – Write p90 latency – Tigris vs S3](./run-sjc-s3-tigris-update-latency_p90_ms.webp "Write p90 latency – Tigris vs S3")

_Figure 10: Write p90 latency during mixed workload (Tigris vs S3)._

Write-side tail latency tracks proportionally: **< 17 ms** for Tigris, **≈ 41
ms** for S3, and **> 680 ms** for R2.

To summarize:

_Table 3: Read and throughput metrics._

| Service          | P50 Latency (ms)            | P90 Latency (ms)            | Runtime (sec)              | Throughput (ops/sec)            |
| ---------------- | --------------------------- | --------------------------- | -------------------------- | ------------------------------- |
| <R t="Tigris" /> | <B t={5.399} unit="ms" />   | <B t={7.867} unit="ms" />   | <B t={241.7} unit="sec" /> | <B t={3309.8} unit="ops/sec" /> |
| <R t="S3" />     | <M t={5.399} s={22.415} />  | <M t={7.867} s={42.047} />  | <S t={241.7} s={896.8} />  | <O t={3309.8} s={891.5} />      |
| <R t="R2" />     | <M t={5.399} s={605.695} /> | <M t={7.867} s={680.959} /> | <S t={241.7} s={4705.3} /> | <O t={3309.8} s={42.6} />       |

_Table 4: Update and throughput metrics._

| Service          | P50 Latency (ms)             | P90 Latency (ms)             | Runtime (sec)              | Throughput (ops/sec)           |
| ---------------- | ---------------------------- | ---------------------------- | -------------------------- | ------------------------------ |
| <R t="Tigris" /> | <B t={12.855} unit="ms" />   | <B t={16.543} unit="ms" />   | <B t={241.6} unit="sec" /> | <B t={828.1} unit="ops/sec" /> |
| <R t="S3" />     | <M t={12.855} s={26.975} />  | <M t={16.543} s={41.215} />  | <S t={241.6} s={896.8} />  | <O t={828.1} s={223.6} />      |
| <R t="R2" />     | <M t={12.855} s={605.695} /> | <M t={16.543} s={680.959} /> | <S t={241.6} s={4705.3} /> | <O t={828.1} s={42.6} />       |

## Conclusion

Tigris outperforms S3 and R2 for small object workloads. The performance
advantage stems from Tigris's optimized architecture for small objects. While S3
and R2 struggle with high latency on small payloads (R2's p90 PUT latency
reaches 340ms), Tigris maintains consistent low latency through intelligent
object inlining, key coalescing, and LSM-backed caching.

These results demonstrate that Tigris can serve as a unified storage solution
for mixed workloads, eliminating the need to maintain separate systems for small
and large objects. Whether you're storing billions of tiny metadata files or
streaming gigabytes of video data, Tigris delivers optimal performance across
the entire object size spectrum.

You can find the full benchmark results in the
[ycsb-benchmarks](https://github.com/tigrisdata-community/ycsb-benchmarks)
repository.
